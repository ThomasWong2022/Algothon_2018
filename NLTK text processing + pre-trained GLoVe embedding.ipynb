{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Merrick\\Downloads\\Resampled_data.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.any of         time    bid    ask  News_count\n",
       "0      False  False  False       False\n",
       "1      False  False  False       False\n",
       "2      False  False  False       False\n",
       "3      False  False  False       False\n",
       "4      False  False  False       False\n",
       "5      False  False  False       False\n",
       "6      False  False  False       False\n",
       "7      False  False  False       False\n",
       "8      False  False  False       False\n",
       "9      False  False  False       False\n",
       "10     False  False  False       False\n",
       "11     False  False  False       False\n",
       "12     False  False  False       False\n",
       "13     False  False  False       False\n",
       "14     False  False  False       False\n",
       "15     False  False  False       False\n",
       "16     False  False  False       False\n",
       "17     False  False  False       False\n",
       "18     False  False  False       False\n",
       "19     False  False  False       False\n",
       "20     False  False  False       False\n",
       "21     False  False  False       False\n",
       "22     False  False  False       False\n",
       "23     False  False  False       False\n",
       "24     False  False  False       False\n",
       "25     False  False  False       False\n",
       "26     False  False  False       False\n",
       "27     False  False  False       False\n",
       "28     False  False  False       False\n",
       "29     False  False  False       False\n",
       "...      ...    ...    ...         ...\n",
       "34963  False  False  False       False\n",
       "34964  False  False  False       False\n",
       "34965  False  False  False       False\n",
       "34966  False  False  False       False\n",
       "34967  False  False  False       False\n",
       "34968  False  False  False       False\n",
       "34969  False  False  False       False\n",
       "34970  False  False  False       False\n",
       "34971  False  False  False       False\n",
       "34972  False  False  False       False\n",
       "34973  False  False  False       False\n",
       "34974  False  False  False       False\n",
       "34975  False  False  False       False\n",
       "34976  False  False  False       False\n",
       "34977  False  False  False       False\n",
       "34978  False  False  False       False\n",
       "34979  False  False  False       False\n",
       "34980  False  False  False       False\n",
       "34981  False  False  False       False\n",
       "34982  False  False  False       False\n",
       "34983  False  False  False       False\n",
       "34984  False  False  False       False\n",
       "34985  False  False  False       False\n",
       "34986  False  False  False       False\n",
       "34987  False  False  False       False\n",
       "34988  False  False  False       False\n",
       "34989  False  False  False       False\n",
       "34990  False  False  False       False\n",
       "34991  False  False  False       False\n",
       "34992  False  False  False       False\n",
       "\n",
       "[34993 rows x 4 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    # SnowballStemmer, PorterStemmer, LemmanizerStemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "return text\n",
    "df['titles'] = df['titles'].map(lambda x: clean_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['titles'])\n",
    "sequences = tokenizer.texts_to_sequences(df['titles'])\n",
    "data = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(20000, 100, input_length=50))\n",
    "# model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(data, np.array(labels), validation_split=0.4, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embds = model.layers[0].get_weights()[\n",
    "# ist = []\n",
    "# for word, i in tokenizer.word_index.items():\n",
    "#     word_list.append(word)\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(word_weights)\n",
    "# number_of_words = 1000\n",
    "# trace = go.Scatter(\n",
    "#     x = X_embedded[0:number_of_words,0], \n",
    "#     y = X_embedded[0:number_of_words, 1],\n",
    "#     mode = 'markers',\n",
    "#     text= word_list[0:number_of_words]\n",
    "# )\n",
    "# layout = dict(title= 't-SNE 1 vs t-SNE 2 for sirst 1000 words ',\n",
    "#               yaxis = dict(title='t-SNE 2'),\n",
    "#               xaxis = dict(title='t-SNE 1'),\n",
    "#               hovermode= 'closest')\n",
    "# fig = dict(data = [trace], layout= layout)\n",
    "# py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model\n",
    "model_glove = Sequential()\n",
    "model_glove.add(Embedding(vocabulary_size, 100, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "model_glove.add(Dropout(0.2))\n",
    "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
    "model_glove.add(MaxPooling1D(pool_size=4))\n",
    "model_glove.add(LSTM(100))\n",
    "model_glove.add(Dense(1, activation='sigmoid'))\n",
    "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "## Fit train data\n",
    "model_glove.fit(data, np.array(labels), validation_split=0.4, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get weights\n",
    "conv_embds = model_conv.layers[0].get_weights()[0]\n",
    "## Plotting function\n",
    "def plot_words(data, start, stop, step):\n",
    "    trace = go.Scatter(\n",
    "        x = data[start:stop:step,0], \n",
    "        y = data[start:stop:step, 1],\n",
    "        mode = 'markers',\n",
    "        text= word_list[start:stop:step]\n",
    "    )\n",
    "    layout = dict(title= 't-SNE 1 vs t-SNE 2',\n",
    "                  yaxis = dict(title='t-SNE 2'),\n",
    "                  xaxis = dict(title='t-SNE 1'),\n",
    "                  hovermode= 'closest')\n",
    "    fig = dict(data = [trace], layout= layout)\n",
    "    py.iplot(fig)\n",
    "\n",
    "## Visualize words in two dimensions \n",
    "glove_tsne_embds = TSNE(n_components=2).fit_transform(glove_emds)\n",
    "plot_words(glove_tsne_embds, 0, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
